{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import warnings\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST, ImageFolder\n",
    "from torchvision.transforms import ToTensor, Resize, Compose, CenterCrop, Normalize\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.metrics.functional import classification, f1\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "import fastai.vision.augment\n",
    "import fastai.vision.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ImageFolderDataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, data_dir, batch_size, transform=None, num_workers=0):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.transform = transform\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def prepare_data(self, stage=None):\n",
    "        pass\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        data_dir = self.data_dir\n",
    "        transform = self.transform\n",
    "        \n",
    "        self.dls = fastai.vision.data.ImageDataLoaders.from_folder(data_dir, item_tfms=fastai.vision.augment.Resize(224))\n",
    "        self.trainset = ImageFolder(os.path.join(data_dir, 'train'), transform)\n",
    "        self.valset = ImageFolder(os.path.join(data_dir, 'val'), transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.trainset, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.valset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'Datasets/cifar10'\n",
    "\n",
    "transform = Compose([\n",
    "        Resize(256, interpolation=2),\n",
    "        CenterCrop(224),\n",
    "        ToTensor(),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "dm = ImageFolderDataModule(data_dir, 32, transform, 8)\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in dm.train_dataloader():\n",
    "    test_eq(type(x), torch.Tensor) \n",
    "    test_eq(type(y), torch.Tensor) \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CNNModule(pl.LightningModule):\n",
    "    def __init__(self, model=None, pretrained=False, freeze_extractor=False, log_level=10, num_classes=None, weight_path=None):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.pretrained = pretrained\n",
    "        self.freeze_extractor = freeze_extractor\n",
    "\n",
    "        assert model is not None, 'Select model from torchvision'\n",
    "        assert num_classes is not None, 'Must configure number of classes with num_classes'\n",
    "        \n",
    "        if not model.startswith('resnet'):\n",
    "            warnings.warn('models other than resnet variants may need different setup for finetuning to work.')\n",
    "            \n",
    "        # Prepare model for finetuning\n",
    "        if weight_path is not None:\n",
    "            param = torch.load(weight_path)\n",
    "            backbone = eval(f'torchvision.models.{model}(pretrained={False})')     \n",
    "            backbone.load_state_dict(param)\n",
    "        else:\n",
    "            backbone = eval(f'torchvision.models.{model}(pretrained={pretrained})')        \n",
    "                    \n",
    "        num_filters = backbone.fc.in_features\n",
    "        layers = list(backbone.children())[:-1]\n",
    "        \n",
    "        self.feature_extractor = torch.nn.Sequential(*layers)\n",
    "        self.classifier = nn.Linear(num_filters, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        if self.freeze_extractor:\n",
    "            with torch.no_grad():\n",
    "                representations = self.feature_extractor(x).flatten(1)\n",
    "        else:\n",
    "            representations = self.feature_extractor(x).flatten(1)\n",
    "\n",
    "        y = self.classifier(representations)\n",
    "        return y\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        \n",
    "        outputs = self.calculate_metrics(y_hat=y_hat, y=y)\n",
    "        return outputs\n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "        avg_metrics = {}\n",
    "        for metric in outputs[0].keys():\n",
    "            val = torch.stack([x[metric] for x in outputs]).mean()\n",
    "            self.logger.experiment.add_scalar(f\"{metric}/train\", val, self.current_epoch)\n",
    "            avg_metrics[metric] = val\n",
    "\n",
    "#         epoch_dictionary = {'loss': avg_metrics['loss']}\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        \n",
    "        outputs = self.calculate_metrics(y_hat=y_hat, y=y)\n",
    "        return outputs\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_metrics = {}\n",
    "        for metric in outputs[0].keys():\n",
    "            val = torch.stack([x[metric] for x in outputs]).mean()\n",
    "            self.logger.experiment.add_scalar(f\"{metric}/validation\", val, self.current_epoch)\n",
    "            avg_metrics[metric] = val\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.02, weight_decay=1e-04)\n",
    "#     >    return torch.optim.SGF(self.parameters(), lr=self.lr, aldsfk'a)\n",
    "    \n",
    "    \n",
    "    def calculate_metrics(self, y, y_hat):\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        y_pred = y_hat.argmax(dim=1)\n",
    "        acc = classification.accuracy(y_pred, y)\n",
    "        f1_score = f1(y_pred, y, self.num_classes)\n",
    "        return {\n",
    "            \"loss\":loss,\n",
    "            \"acc\": acc,\n",
    "            \"f1\": f1_score\n",
    "        }\n",
    "    \n",
    "    def on_sanity_check_start(self):\n",
    "        self.logger.disable()\n",
    "\n",
    "    def on_sanity_check_end(self):\n",
    "        self.logger.enable() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Running in fast_dev_run mode: will run a full train, val and test loop using 5 batch(es).\n",
      "\n",
      "  | Name              | Type       | Params\n",
      "-------------------------------------------------\n",
      "0 | feature_extractor | Sequential | 11.2 M\n",
      "1 | classifier        | Linear     | 5.1 K \n",
      "-------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb9874a6df4545c890ee8b65f9b8b63c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setup a resnet model\n",
    "modelname = 'resnet18'\n",
    "model = CNNModule(modelname, pretrained=True, num_classes=len(dm.trainset.classes))\n",
    "\n",
    "# Run a trial `fast_dev_run` of 5 iterations on the trainset\n",
    "trainer = pl.Trainer(gpus=1, checkpoint_callback=False, fast_dev_run=5)\n",
    "test_eq(trainer.fit(model, dm), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

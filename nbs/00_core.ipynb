{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import fastai.vision.augment\n",
    "import fastai.vision.data\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST, ImageFolder\n",
    "from torchvision.transforms import CenterCrop, Compose, Normalize, Resize, ToTensor\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.metrics.functional import classification, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ImageFolderDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir, batch_size, transform=None, num_workers=0):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.transform = transform\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def prepare_data(self, stage=None):\n",
    "        pass\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        data_dir = self.data_dir\n",
    "        transform = self.transform\n",
    "\n",
    "        self.dls = fastai.vision.data.ImageDataLoaders.from_folder(\n",
    "            data_dir, item_tfms=fastai.vision.augment.Resize(224)\n",
    "        )\n",
    "        self.trainset = ImageFolder(os.path.join(data_dir, \"train\"), transform)\n",
    "        self.valset = ImageFolder(os.path.join(data_dir, \"val\"), transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.trainset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.valset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of how to use a datamodule with transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"datasets/cifar10\"\n",
    "\n",
    "transform = Compose(\n",
    "    [\n",
    "        Resize(256, interpolation=2),\n",
    "        CenterCrop(224),\n",
    "        ToTensor(),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dm = ImageFolderDataModule(data_dir, 32, transform, 8)\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataloaders can be accesed from the datamodule like so,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in dm.train_dataloader():\n",
    "    test_eq(type(x), torch.Tensor)\n",
    "    test_eq(type(y), torch.Tensor)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.utilities import rank_zero_only\n",
    "from pytorch_lightning.loggers import LightningLoggerBase\n",
    "from pytorch_lightning.loggers.base import rank_zero_experiment\n",
    "from rich import print\n",
    "\n",
    "class LightWeightLogger(LightningLoggerBase):\n",
    "    \"\"\"A light weight logger that doesn't save any logs, it will just print to the command line\"\"\"\n",
    "    @property\n",
    "    def name(self):\n",
    "        return 'LightWeightLogger'\n",
    "\n",
    "    @property\n",
    "    @rank_zero_experiment\n",
    "    def experiment(self):\n",
    "        # Return the experiment object associated with this logger.\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def version(self):\n",
    "        # Return the experiment version, int or str.\n",
    "        return '0.1'\n",
    "\n",
    "    @rank_zero_only\n",
    "    def log_hyperparams(self, params):\n",
    "        # params is an argparse.Namespace\n",
    "        # your code to record hyperparameters goes here\n",
    "        pass\n",
    "\n",
    "    @rank_zero_only\n",
    "    def log_metrics(self, metrics, step):\n",
    "        # metrics is a dictionary of metric names and values\n",
    "        # your code to record metrics goes here\n",
    "        print(step, metrics)\n",
    "        pass\n",
    "\n",
    "    def save(self):\n",
    "        # Optional. Any code necessary to save logger data goes here\n",
    "        pass\n",
    "\n",
    "    @rank_zero_only\n",
    "    def finalize(self, status):\n",
    "        # Optional. Any code that needs to be run after training\n",
    "        # finishes goes here\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class CNNModule(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model=None,\n",
    "        pretrained=False,\n",
    "        freeze_extractor=False,\n",
    "        log_level=10,\n",
    "        num_classes=None,\n",
    "        weight_path=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.pretrained = pretrained\n",
    "        self.freeze_extractor = freeze_extractor\n",
    "\n",
    "        assert model is not None, \"Select model from torchvision\"\n",
    "        assert (\n",
    "            num_classes is not None\n",
    "        ), \"Must configure number of classes with num_classes\"\n",
    "\n",
    "        if not model.startswith(\"resnet\"):\n",
    "            warnings.warn(\n",
    "                \"models other than resnet variants may need different setup for finetuning to work.\"\n",
    "            )\n",
    "\n",
    "        # Prepare model for finetuning\n",
    "        if weight_path is not None:\n",
    "            param = torch.load(weight_path)\n",
    "            backbone = eval(f\"torchvision.models.{model}(pretrained={False})\")\n",
    "            backbone.load_state_dict(param)\n",
    "        else:\n",
    "            backbone = eval(f\"torchvision.models.{model}(pretrained={pretrained})\")\n",
    "\n",
    "        num_filters = backbone.fc.in_features\n",
    "        layers = list(backbone.children())[:-1]\n",
    "\n",
    "        self.feature_extractor = torch.nn.Sequential(*layers)\n",
    "        self.classifier = nn.Linear(num_filters, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        if self.freeze_extractor:\n",
    "            with torch.no_grad():\n",
    "                representations = self.feature_extractor(x).flatten(1)\n",
    "        else:\n",
    "            representations = self.feature_extractor(x).flatten(1)\n",
    "\n",
    "        y = self.classifier(representations)\n",
    "        return y\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "\n",
    "        outputs = self.calculate_metrics(y_hat=y_hat, y=y)\n",
    "        return outputs\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        avg_metrics = {}\n",
    "        for metric in outputs[0].keys():\n",
    "            val = torch.stack([x[metric] for x in outputs]).mean()\n",
    "            self.logger.experiment.add_scalar(\n",
    "                f\"{metric}/train\", val, self.current_epoch\n",
    "            )\n",
    "            avg_metrics[metric] = val\n",
    "\n",
    "    #         epoch_dictionary = {'loss': avg_metrics['loss']}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "\n",
    "        outputs = self.calculate_metrics(y_hat=y_hat, y=y)\n",
    "        return outputs\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_metrics = {}\n",
    "        for metric in outputs[0].keys():\n",
    "            val = torch.stack([x[metric] for x in outputs]).mean()\n",
    "            self.logger.experiment.add_scalar(\n",
    "                f\"{metric}/validation\", val, self.current_epoch\n",
    "            )\n",
    "            avg_metrics[metric] = val\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.02, weight_decay=1e-04)\n",
    "\n",
    "    #     >    return torch.optim.SGF(self.parameters(), lr=self.lr, aldsfk'a)\n",
    "\n",
    "    def calculate_metrics(self, y, y_hat):\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        y_pred = y_hat.argmax(dim=1)\n",
    "        acc = classification.accuracy(y_pred, y)\n",
    "        f1_score = f1(y_pred, y, self.num_classes)\n",
    "        return {\"loss\": loss, \"acc\": acc, \"f1\": f1_score}\n",
    "\n",
    "    def on_sanity_check_start(self):\n",
    "        self.logger.disable()\n",
    "\n",
    "    def on_sanity_check_end(self):\n",
    "        self.logger.enable()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type       | Params\n",
      "-------------------------------------------------\n",
      "0 | feature_extractor | Sequential | 11.2 M\n",
      "1 | classifier        | Linear     | 5.1 K \n",
      "-------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b687c161a84e408b08075adc077861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Validation sanity check: 0it [00:00, ?it/s]"
     },
     "metadata": {
      "transient": {}
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e375c24a55541268f849d46faf92396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Training: 0it [00:00, ?it/s]"
     },
     "metadata": {
      "transient": {}
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3ff75554e78443eb2d3a5d116a6aa23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Validating: 0it [00:00, ?it/s]"
     },
     "metadata": {
      "transient": {}
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0512ebf60fb40f5ba2148db6aec294e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Validating: 0it [00:00, ?it/s]"
     },
     "metadata": {
      "transient": {}
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43812cea52f342b798f8c53fbca872c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Validating: 0it [00:00, ?it/s]"
     },
     "metadata": {
      "transient": {}
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setup a resnet model\n",
    "modelname = 'resnet18'\n",
    "model = CNNModule(modelname, pretrained=True, num_classes=len(dm.trainset.classes))\n",
    "\n",
    "# Setup logger\n",
    "logger = LightWeightLogger()\n",
    "\n",
    "# Run a trial `fast_dev_run` of 5 iterations on the trainset\n",
    "trainer = pl.Trainer(gpus=1, checkpoint_callback=False, max_epochs=10, logger=logger)\n",
    "test_eq(trainer.fit(model, dm), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from contexttimer import Timer\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "def multiclass_report(x_train, y_train, x_val, y_val, clf=None, dataset_name=None):\n",
    "    \"\"\"Utility function to score classifier\n",
    "    Pass in the classifier if you want to test train, test times etc.\n",
    "    \"\"\"\n",
    "    n_classes = len(set(y_train))\n",
    "    labels = sorted(list(set(y_train)))\n",
    "    \n",
    "    with Timer() as train_time:\n",
    "        clf.fit(x_train, y_train)\n",
    "        \n",
    "    with Timer() as test_time:\n",
    "        y_pred_proba = clf.predict_proba(x_val)\n",
    "        \n",
    "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "        \n",
    "    results = {\n",
    "        'Train time': train_time.elapsed,\n",
    "        'Test time': test_time.elapsed\n",
    "    }\n",
    "    results['clf'] = clf.__class__.__name__\n",
    "    results['dataset'] = dataset_name\n",
    "    results['Weighted Fscore'] = metrics.f1_score(y_val, y_pred, average='weighted')\n",
    "    results['Top-1 score'] = metrics.top_k_accuracy_score(y_val, y_pred_proba, k=1)\n",
    "    results['Top-5 score'] = metrics.top_k_accuracy_score(y_val, y_pred_proba, k=5) if n_classes > 5 else None\n",
    "    results['n_classes'] = n_classes\n",
    "    results['n_train_samples'] = len(x_train)\n",
    "    results['n_test_samples'] = len(x_val)\n",
    "        \n",
    "    return results\n",
    "        \n",
    "x_train, y_train = zip(*[(np.asarray(x),y) for x, y in dm.trainset])\n",
    "x_val, y_val = zip(*[(np.asarray(x),y) for x, y in dm.valset])\n",
    "clf = DummyClassifier(strategy=\"prior\")\n",
    "res = multiclass_report(clf, x_train, y_train, x_val, y_val)\n",
    "pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "output_type": "error",
     "traceback": [
      "Error: Session cannot generate requests",
      "at b.executeCodeCell (/root/.vscode-server-insiders/extensions/ms-toolsai.jupyter-2020.12.414227025/out/client/extension.js:49:701508)",
      "at b.execute (/root/.vscode-server-insiders/extensions/ms-toolsai.jupyter-2020.12.414227025/out/client/extension.js:49:701062)",
      "at /root/.vscode-server-insiders/extensions/ms-toolsai.jupyter-2020.12.414227025/out/client/extension.js:49:697679"
     ]
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}